"""
API –¥–ª—è —Ä–µ–∞–ª-—Ç–∞–π–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ fraud_model_production/
"""

import joblib
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any
import json

from config import MODEL_DIR
from dtos import TransactionOutput, TransactionInput, Stats, Models


class FraudDetectionAPI:
    """
    API –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ñ—Ä–æ–¥–∞
    """

    def __init__(self, model_path: str = MODEL_DIR):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        """
        print(f"Loading model from {model_path}...")
        self.model_pkg = joblib.load(model_path)

        self.iso = self.model_pkg['iso']
        self.catboost = self.model_pkg['catboost']
        self.xgboost = self.model_pkg['xgboost']
        self.lightgbm = self.model_pkg['lightgbm']
        self.threshold = self.model_pkg['threshold']
        self.feature_cols = self.model_pkg['feature_cols']
        self.encoders = self.model_pkg['encoders']
        self.weights = self.model_pkg['ensemble_weights']
        self.history = self.model_pkg.get('history', {})

        print(f"‚úì Model loaded successfully")
        print(f"  Version: {self.model_pkg.get('version', 'unknown')}")
        print(f"  Threshold: {self.threshold:.4f}")
        print(f"  Features: {len(self.feature_cols)}")

    def predict_single_transaction(
            self,
            transaction: TransactionInput,
            behavioral_patterns: Dict[str, Any] = None
    ) -> TransactionOutput:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ñ—Ä–æ–¥–∞ –¥–ª—è –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏

        Args:
            transaction: —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
                Required: cst_dim_id, transdatetime, amount, direction
            behavioral_patterns: —Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –∫–ª–∏–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            TransactionOutput (
                is_fraud: bool
                fraud_probability: float
                risk_level: str
                alerts: list
                processing_time_ms: float
            )
        """
        start_time = datetime.now()
        transaction_dict = transaction.model_dump()

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        required_fields = ['cst_dim_id', 'transdatetime', 'amount', 'direction']
        for field in required_fields:
            if field not in transaction_dict:
                raise ValueError(f"Missing required field: {field}")

        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∏—á–µ–π
        features = self._build_features(transaction, behavioral_patterns)

        # Anomaly score
        X_single = pd.DataFrame([features])[self.feature_cols]
        X_single = X_single.apply(pd.to_numeric, errors='coerce').fillna(0)

        anomaly_score = -self.iso.decision_function(X_single)[0]
        X_single['anomaly_score'] = anomaly_score

        # –ê–Ω—Å–∞–º–±–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        p_cat = self.catboost.predict_proba(X_single)[0, 1]
        p_xgb = self.xgboost.predict_proba(X_single)[0, 1]
        p_lgb = self.lightgbm.predict_proba(X_single)[0, 1]

        fraud_prob = (
                self.weights[0] * p_cat +
                self.weights[1] * p_xgb +
                self.weights[2] * p_lgb
        )

        is_fraud = fraud_prob >= self.threshold

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞
        if fraud_prob >= 0.8:
            risk_level = "CRITICAL"
        elif fraud_prob >= 0.6:
            risk_level = "HIGH"
        elif fraud_prob >= 0.4:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–ª–µ—Ä—Ç—ã
        alerts = self._generate_alerts(transaction, features, fraud_prob)

        # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é (–¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π)
        self._update_history(transaction)

        processing_time = (datetime.now() - start_time).total_seconds() * 1000

        return TransactionOutput(
            is_fraud=bool(is_fraud),
            fraud_probability=float(fraud_prob),
            risk_level=risk_level,
            alerts=alerts,
            processing_time_ms=processing_time,
            model_version=self.model_pkg.get('version', 'unknown'),
            threshold_used=self.threshold,
            individual_scores=Models(
                catboost=float(p_cat),
                xgboost=float(p_xgb),
                lightgbm=float(p_lgb),
                anomaly=float(anomaly_score),
            )
        )

    def predict_batch(
            self,
            transactions: List[TransactionInput],
            behavioral_patterns: Dict[int, Dict[str, Any]] = None
    ) -> List[TransactionOutput]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
        """
        results = []
        for trans in transactions:
            cst_id = trans.cst_dim_id
            patterns = behavioral_patterns.get(cst_id) if behavioral_patterns else None
            result = self.predict_single_transaction(trans, patterns)
            results.append(result)

        return results

    def _build_features(
            self,
            transaction: TransactionInput,
            behavioral_patterns: Dict[str, Any] = None
    ) -> Dict[str, float]:
        """
        –°—Ç—Ä–æ–∏—Ç —Ñ–∏—á–∏ –¥–ª—è –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        """
        cst_id = transaction.cst_dim_id
        ts = pd.to_datetime(transaction.transdatetime)
        amount = float(transaction.amount)
        direction = str(transaction.direction)

        # –ò—Å—Ç–æ—Ä–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        hist = self.history.get(cst_id, [])

        cutoff_7 = ts - timedelta(days=7)
        cutoff_30 = ts - timedelta(days=30)
        recent_7 = [h for h in hist if h[0] >= cutoff_7 and h[0] < ts]
        recent_30 = [h for h in hist if h[0] >= cutoff_30 and h[0] < ts]

        features = {}

        # –ë–∞–∑–æ–≤—ã–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ
        features['num_trans_last_7d'] = len(recent_7)
        features['num_trans_last_30d'] = len(recent_30)
        features['sum_amount_last_7d'] = sum(h[1] for h in recent_7)
        features['sum_amount_last_30d'] = sum(h[1] for h in recent_30)

        avg_7 = features['sum_amount_last_7d'] / features['num_trans_last_7d'] if features[
                                                                                      'num_trans_last_7d'] > 0 else 0
        avg_30 = features['sum_amount_last_30d'] / features['num_trans_last_30d'] if features[
                                                                                         'num_trans_last_30d'] > 0 else 0

        features['avg_amount_last_7d'] = avg_7
        features['avg_amount_last_30d'] = avg_30

        # Velocity
        features['velocity_7d'] = features['num_trans_last_7d'] / 7.0
        features['velocity_30d'] = features['num_trans_last_30d'] / 30.0
        features['amount_velocity_7d'] = features['sum_amount_last_7d'] / 7.0
        features['amount_velocity_30d'] = features['sum_amount_last_30d'] / 30.0
        features['velocity_acceleration'] = features['velocity_7d'] - features['velocity_30d']

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        amounts_7d = [h[1] for h in recent_7]
        features['std_amount_7d'] = np.std(amounts_7d) if len(amounts_7d) > 1 else 0
        features['max_amount_7d'] = max(amounts_7d) if amounts_7d else 0
        features['min_amount_7d'] = min(amounts_7d) if amounts_7d else 0

        # Ratios
        features['ratio_num_7_30'] = features['num_trans_last_7d'] / features['num_trans_last_30d'] if features[
                                                                                                           'num_trans_last_30d'] > 0 else 0
        features['ratio_sum_7_30'] = features['sum_amount_last_7d'] / features['sum_amount_last_30d'] if features[
                                                                                                             'sum_amount_last_30d'] > 0 else 0
        features['amount_ratio_avg7'] = amount / avg_7 if avg_7 > 0 else 0
        features['amount_ratio_avg30'] = amount / avg_30 if avg_30 > 0 else 0
        features['amount_to_max_ratio'] = amount / features['max_amount_7d'] if features['max_amount_7d'] > 0 else 0

        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ
        last_ts = hist[-1][0] if hist else None
        features['time_since_last_hours'] = (ts - last_ts).total_seconds() / 3600.0 if last_ts else 0
        features['time_since_last_squared'] = features['time_since_last_hours'] ** 2

        first_ts = hist[0][0] if hist else ts
        features['days_since_first'] = (ts - first_ts).days
        features['trans_frequency'] = len(hist) / features['days_since_first'] if features[
                                                                                      'days_since_first'] > 0 else 0

        # –ì—Ä–∞—Ñ–æ–≤—ã–µ
        features['num_prev_trans_to_same'] = sum(1 for h in hist if h[2] == direction and h[0] < ts)
        features['total_prev_trans'] = len([h for h in hist if h[0] < ts])
        features['unique_directions_count'] = len(set(h[2] for h in hist if h[0] < ts))

        # –ì—Ä–∞—Ñ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ, –±–µ–∑ –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)
        features['sender_out_degree'] = features['unique_directions_count']
        features['receiver_in_degree'] = 1  # –ù–µ –º–æ–∂–µ–º –ø–æ—Å—á–∏—Ç–∞—Ç—å –±–µ–∑ –¥—Ä—É–≥–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤
        features['pair_count'] = features['num_prev_trans_to_same']

        # –ê–Ω–æ–º–∞–ª–∏–∏
        features['is_amount_spike'] = 1 if (avg_30 > 0 and amount > avg_30 * 3) else 0
        features['is_rapid_repeat'] = 1 if (
                features['time_since_last_hours'] < 1.0 and features['time_since_last_hours'] > 0) else 0

        hour = ts.hour
        features['is_night_transaction'] = 1 if (hour >= 23 or hour <= 6) else 0
        features['is_weekend'] = 1 if ts.dayofweek in [5, 6] else 0

        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
        features['hour'] = hour
        features['dayofweek'] = ts.dayofweek
        features['month'] = ts.month
        features['amount'] = amount
        features['amount_log'] = np.log1p(amount)

        # –≠–Ω–∫–æ–¥–∏–Ω–≥ direction
        if 'direction' in self.encoders:
            le = self.encoders['direction']
            if direction in le.classes_:
                features['direction'] = le.transform([direction])[0]
            else:
                features['direction'] = le.transform([le.classes_[0]])[0]
        else:
            features['direction'] = 0

        # –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if behavioral_patterns:
            for key, value in behavioral_patterns.items():
                if key not in ['cst_dim_id', 'transdate']:
                    features[key] = value
        else:
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            for col in self.feature_cols:
                if col not in features:
                    features[col] = 0

        return features

    def _generate_alerts(
            self,
            transaction: TransactionInput,  # not actual
            features: Dict[str, float],
            fraud_prob: float
    ) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º—ã–µ –∞–ª–µ—Ä—Ç—ã
        """
        alerts = []

        if features.get('is_amount_spike', 0) == 1:
            alerts.append("‚ö†Ô∏è Amount is 3x higher than 30-day average")

        if features.get('is_rapid_repeat', 0) == 1:
            alerts.append("‚ö†Ô∏è Transaction less than 1 hour since last one")

        if features.get('is_night_transaction', 0) == 1:
            alerts.append("‚ö†Ô∏è Transaction during night hours (23:00-06:00)")

        if features.get('velocity_acceleration', 0) > 2:
            alerts.append("‚ö†Ô∏è Sudden increase in transaction velocity")

        if features.get('total_prev_trans', 0) < 5:
            alerts.append("‚ö†Ô∏è New customer with limited history")

        if fraud_prob > 0.9:
            alerts.append("üö® CRITICAL: Very high fraud probability")

        return alerts

    def _update_history(self, transaction: TransactionInput):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∫–ª–∏–µ–Ω—Ç–∞
        """
        cst_id = transaction.cst_dim_id
        ts = pd.to_datetime(transaction.transdatetime)
        amount = float(transaction.amount)
        direction = str(transaction.direction)

        if cst_id not in self.history:
            self.history[cst_id] = []

        self.history[cst_id].append((ts, amount, direction))

        # –•—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 60 –¥–Ω–µ–π
        cutoff = ts - timedelta(days=60)
        self.history[cst_id] = [h for h in self.history[cst_id] if h[0] >= cutoff]

    def get_stats(self) -> Stats:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É API
        """
        return Stats(
            total_customers_in_history=len(self.history),
            model_version=self.model_pkg.get('version', 'unknown'),
            threshold=self.threshold,
            num_features=len(self.feature_cols),
        )
